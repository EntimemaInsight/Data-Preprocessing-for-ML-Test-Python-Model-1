{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0b23ce",
   "metadata": {},
   "source": [
    "# Data Preprocessing for ML - Test Python Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42fd7a",
   "metadata": {},
   "source": [
    "This project demonstrates the important steps of data preprocessing, including handling missing data, encoding categorical variables, and scaling numerical features, to prepare the data for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35c1a2",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fc596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f6c5c",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9690ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "data = pd.read_csv(\"C:/Users/aleksandar.dimitrov/Desktop/Python Tests/Data/CategoricalData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67730d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50a996",
   "metadata": {},
   "source": [
    "## Handling Missing Data with Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809a11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Creating Matrix of the features (independent Variables)\n",
    "X = data.iloc[:, :-1].values\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5619702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Creating The dependant Variable Vector\n",
    "Y = data.iloc[:, 3].values\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda296f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 48000.0]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 27.0 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278fa2a",
   "metadata": {},
   "source": [
    "## Encoding the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02384a1c",
   "metadata": {},
   "source": [
    " We should keep in mind that some machine learning algorithms may incorrectly interpret numerical labels as ordinal values and assume a certain order or magnitude between them. For example, if the labels are encoded as 0, 1, and 2, the algorithm might incorrectly assume that 2 is greater than 1 and 1 is greater than 0. This can lead to incorrect interpretations and predictions. Therefore, it is preferable to use OneHotEncoder instead of LabelEncoder, depending on the nature of your data and the requirements of your machine learning algorithm. \n",
    " However, for presentation purposes, we are using LabelEncoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d1c628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 1 0 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding of categorical feature\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "print(X[:, 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c335c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 48000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 27.0 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy Encoding (One-Hot Encoding) using ColumnTransformer\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813da71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Categorical data\n",
    "labelencoder_y = LabelEncoder()\n",
    "Y = labelencoder_y.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4527a4",
   "metadata": {},
   "source": [
    "We create training and test set. \n",
    "Train Set:\n",
    "\n",
    "1. The training set consists of 8 instances, representing 8 different people with their features (attributes) and labels (target values).\n",
    "2. The feature matrix, denoted as X_train, has a shape of (8, 5), indicating it has 8 instances and 5 features (attributes).\n",
    "3. The label vector, denoted as y_train, has a shape of (8,), indicating it has 8 labels (target values).\n",
    "\n",
    "Test Set:\n",
    "\n",
    "1. The test set contains 2 instances with their respective features and labels.\n",
    "2. The feature matrix, denoted as X_test, has a shape of (2, 5), indicating it has 2 instances and 5 features (attributes).\n",
    "3. The label vector, denoted as y_test, has a shape of (2,), indicating it has 2 labels (target values).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63054da",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the training Set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb020d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes:\n",
      "X_train: (8, 5)\n",
      "y_train: (8,)\n",
      "Test set shapes:\n",
      "X_test: (2, 5)\n",
      "y_test: (2,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the Dataset into the training Set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print(\"Train set shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", Y_train.shape)\n",
    "\n",
    "print(\"Test set shapes:\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d52ea8",
   "metadata": {},
   "source": [
    "## Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b690e9",
   "metadata": {},
   "source": [
    "With the code below we performs feature scaling on the attributes in the training and test datasets using z-score standardization (StandardScaler) to improve the handling of the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f463f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Training Set:\n",
      "[[-1.00000000e+00  2.64575131e+00 -7.74596669e-01  4.33012702e-01\n",
      "  -1.18512280e+00]\n",
      " [ 1.00000000e+00 -3.77964473e-01 -7.74596669e-01 -2.08166817e-17\n",
      "   5.98428342e-01]\n",
      " [-1.00000000e+00 -3.77964473e-01  1.29099445e+00 -1.44337567e+00\n",
      "  -1.18512280e+00]\n",
      " [-1.00000000e+00 -3.77964473e-01  1.29099445e+00 -1.44337567e+00\n",
      "  -8.09638345e-01]\n",
      " [ 1.00000000e+00 -3.77964473e-01 -7.74596669e-01  1.58771324e+00\n",
      "   1.72488169e+00]\n",
      " [-1.00000000e+00 -3.77964473e-01  1.29099445e+00  1.44337567e-01\n",
      "   3.52016672e-02]\n",
      " [ 1.00000000e+00 -3.77964473e-01 -7.74596669e-01  1.01036297e+00\n",
      "   1.06778390e+00]\n",
      " [ 1.00000000e+00 -3.77964473e-01 -7.74596669e-01 -2.88675135e-01\n",
      "  -2.46411670e-01]]\n",
      "Scaled Test Set:\n",
      "[[-1.          2.64575131 -0.77459667 -1.01036297 -0.62189612]\n",
      " [-1.          2.64575131 -0.77459667  1.87638837  2.10036614]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling(Standardisation and Normalisation)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# Print the scaled training set\n",
    "print(\"Scaled Training Set:\")\n",
    "print(X_train)\n",
    "\n",
    "# Print the scaled test set\n",
    "print(\"Scaled Test Set:\")\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
